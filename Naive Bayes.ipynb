{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自己编写实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入相关模块和包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置中文编码\n",
    "#coding:utf-8\n",
    "# 极大似然估计  朴素贝叶斯算法\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义主函数和NaiveBayes类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    NB = NaiveBayes()\n",
    "    trainData , labels, testData, testlabels = NB.getTrainSet()\n",
    "    NB.test(trainData , labels, testData, testlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes():\n",
    "    #获取数据集并处理\n",
    "    def getTrainSet(self):\n",
    "        return trainData , labels, testData, testlabels\n",
    "    \n",
    "    #计算贝叶斯公式各概率及分类\n",
    "    def classify(self,trainData ,labels,features):\n",
    "        pass\n",
    "    \n",
    "    #查看分类结果\n",
    "    def test(trainData , labels, testData, testlabels):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义getTrainSet函数：读取并切分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainSet(self):\n",
    "        dataset = pd.read_csv('Iris.csv')\n",
    "        #重命名各属性名称\n",
    "        dataset = dataset.rename(columns = {'5.1':'Feature_1',\n",
    "                         '3.5':'Feature_2',\n",
    "                         '1.4':'Feature_3',\n",
    "                         '0.2':'Feature_4',\n",
    "                         'Iris-setosa':'labels'})\n",
    "        datasetNP = np.array(dataset)\n",
    "        X = datasetNP[:,:-1]\n",
    "        y = datasetNP[:,-1]\n",
    "        trainData, testData, labels,testlabels = train_test_split(X,y,test_size = 0.3)\n",
    "        return trainData, labels, testData, testlabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_1  Feature_2  Feature_3  Feature_4       labels\n",
       "0        4.9        3.0        1.4        0.2  Iris-setosa\n",
       "1        4.7        3.2        1.3        0.2  Iris-setosa\n",
       "2        4.6        3.1        1.5        0.2  Iris-setosa\n",
       "3        5.0        3.6        1.4        0.2  Iris-setosa\n",
       "4        5.4        3.9        1.7        0.4  Iris-setosa\n",
       "5        4.6        3.4        1.4        0.3  Iris-setosa\n",
       "6        5.0        3.4        1.5        0.2  Iris-setosa\n",
       "7        4.4        2.9        1.4        0.2  Iris-setosa\n",
       "8        4.9        3.1        1.5        0.1  Iris-setosa\n",
       "9        5.4        3.7        1.5        0.2  Iris-setosa"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Iris.csv')\n",
    "dataset = dataset.rename(columns = {'5.1':'Feature_1',\n",
    "                         '3.5':'Feature_2',\n",
    "                         '1.4':'Feature_3',\n",
    "                         '0.2':'Feature_4',\n",
    "                         'Iris-setosa':'labels'})\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义classify函数，计算各概率及分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1、求先验概率p(yi)\n",
    "- 2、求每个特征和每个标签对应的联合概率 p(xi,yi)\n",
    "- 3、求每个特征在每个标签下的条件概率p(xi|yi)\n",
    "- 4、求p(x|y),的连乘式\n",
    "- 5、贝叶斯公式计算P(yi|X)=P(X|yi)p(yi)，求maxP(yi|X)得到分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(self,trainData ,labels,features):\n",
    "        #1、\n",
    "        labels = list(labels)\n",
    "        P_y ={}\n",
    "        for label in labels:\n",
    "            P_y[label] = labels.count(label)/float(len(labels))\n",
    "            \n",
    "        #2/\n",
    "        P_xy = {}\n",
    "        for y in P_y.keys():\n",
    "            y_index = [i for i,label in enumerate(labels) if label == y]\n",
    "            for j in range(len(features)):\n",
    "                x_index = [i for i,feature in enumerate(features) if feature == features[j]]\n",
    "                xy_count = len(set(x_index)) & len(set(y_index))\n",
    "                P_key = str(features[j])+ '*' + str(y)\n",
    "                P_xy[P_key] = xy_count / float(len(labels))\n",
    "                           \n",
    "        #3/求条件概率\n",
    "        P = {}                   \n",
    "        for i in P_y.keys():\n",
    "            for x in features:\n",
    "                pkey = str(x) + '|' + str(y)\n",
    "                p[pkey] = P_xy[str(x) + '*' + str(y)] / float(P_y[y])\n",
    "        \n",
    "        #计算每条数据集所属类别的概率\n",
    "        F = {}\n",
    "        for y in P_y:\n",
    "            F[y] = P_y[y]\n",
    "            for x in features:\n",
    "                F[y] = F[y] * P[str(x) + '*' + str(y)]\n",
    "                \n",
    "        features_label = max(F,key = F.get)\n",
    "        return features_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义test函数，查看训练结果及准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(self,trainData,labels,testData,testlabels):\n",
    "    correct = 0\n",
    "    for i in range(len(testData)):\n",
    "        features = testData[i]\n",
    "        result = nb.classify(trainData ,labels,features)\n",
    "        print(features,'属于'，result)\n",
    "        if result == testlabels[i]:\n",
    "            correct += 1\n",
    "    accuracy = correct / float(len(testlabels))\n",
    "    print('准确率:',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完整代码，并查看训练结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.4 3.9 1.7 0.4] 属于 Iris-setosa\n",
      "[5.8 2.7 4.1 1.0] 属于 Iris-versicolor\n",
      "[5.5 4.2 1.4 0.2] 属于 Iris-setosa\n",
      "[6.6 2.9 4.6 1.3] 属于 Iris-setosa\n",
      "[5.4 3.4 1.5 0.4] 属于 Iris-setosa\n",
      "[6.3 3.3 6.0 2.5] 属于 Iris-setosa\n",
      "[6.1 2.8 4.7 1.2] 属于 Iris-versicolor\n",
      "[6.6 3.0 4.4 1.4] 属于 Iris-setosa\n",
      "[6.7 3.0 5.0 1.7] 属于 Iris-setosa\n",
      "[6.7 3.1 4.7 1.5] 属于 Iris-versicolor\n",
      "[5.7 3.0 4.2 1.2] 属于 Iris-versicolor\n",
      "[5.1 3.8 1.6 0.2] 属于 Iris-setosa\n",
      "[6.4 3.2 5.3 2.3] 属于 Iris-virginica\n",
      "[5.5 2.4 3.8 1.1] 属于 Iris-setosa\n",
      "[6.7 3.0 5.2 2.3] 属于 Iris-virginica\n",
      "[6.3 2.5 5.0 1.9] 属于 Iris-virginica\n",
      "[7.2 3.0 5.8 1.6] 属于 Iris-setosa\n",
      "[4.8 3.0 1.4 0.3] 属于 Iris-setosa\n",
      "[5.1 3.8 1.5 0.3] 属于 Iris-setosa\n",
      "[5.4 3.9 1.3 0.4] 属于 Iris-setosa\n",
      "[7.3 2.9 6.3 1.8] 属于 Iris-setosa\n",
      "[4.3 3.0 1.1 0.1] 属于 Iris-setosa\n",
      "[6.7 3.3 5.7 2.5] 属于 Iris-setosa\n",
      "[5.6 2.5 3.9 1.1] 属于 Iris-versicolor\n",
      "[4.4 2.9 1.4 0.2] 属于 Iris-setosa\n",
      "[5.0 3.5 1.6 0.6] 属于 Iris-setosa\n",
      "[5.8 2.7 3.9 1.2] 属于 Iris-versicolor\n",
      "[5.1 3.4 1.5 0.2] 属于 Iris-setosa\n",
      "[4.9 2.5 4.5 1.7] 属于 Iris-setosa\n",
      "[4.9 2.4 3.3 1.0] 属于 Iris-setosa\n",
      "[7.9 3.8 6.4 2.0] 属于 Iris-setosa\n",
      "[5.8 2.7 5.1 1.9] 属于 Iris-virginica\n",
      "[6.2 2.9 4.3 1.3] 属于 Iris-versicolor\n",
      "[6.7 3.3 5.7 2.1] 属于 Iris-setosa\n",
      "[5.1 3.7 1.5 0.4] 属于 Iris-setosa\n",
      "[4.9 3.1 1.5 0.1] 属于 Iris-setosa\n",
      "[6.1 2.9 4.7 1.4] 属于 Iris-versicolor\n",
      "[6.1 3.0 4.6 1.4] 属于 Iris-versicolor\n",
      "[5.7 4.4 1.5 0.4] 属于 Iris-setosa\n",
      "[6.9 3.1 5.4 2.1] 属于 Iris-virginica\n",
      "[6.4 2.8 5.6 2.1] 属于 Iris-virginica\n",
      "[5.0 2.3 3.3 1.0] 属于 Iris-setosa\n",
      "[5.7 2.6 3.5 1.0] 属于 Iris-versicolor\n",
      "[5.1 3.8 1.9 0.4] 属于 Iris-setosa\n",
      "[6.1 3.0 4.9 1.8] 属于 Iris-virginica\n",
      "准确率: 0.7111111111111111\n"
     ]
    }
   ],
   "source": [
    "class NaiveBayes(object):\n",
    "     def getTrainSet(self):\n",
    "        dataset = pd.read_csv('Iris.csv')\n",
    "        dataset = dataset.rename(columns = {'5.1':'Feature_1',\n",
    "                         '3.5':'Feature_2',\n",
    "                         '1.4':'Feature_3',\n",
    "                         '0.2':'Feature_4',\n",
    "                         'Iris-setosa':'labels'})\n",
    "        datasetNP = np.array(dataset)\n",
    "        X = datasetNP[:,:-1]\n",
    "        y = datasetNP[:,-1]\n",
    "        trainData, testData, labels,testlabels = train_test_split(X,y,test_size = 0.3)\n",
    "        return trainData, labels, testData, testlabels\n",
    "\n",
    "     def classify(self, trainData, labels, features):\n",
    "        #求labels中每个label的先验概率\n",
    "        labels = list(labels)\n",
    "        #转换为list类型\n",
    "        P_y = {}\n",
    "        #用字典存入label及其概率\n",
    "        for label in labels:\n",
    "            P_y[label] = labels.count(label)/float(len(labels))\n",
    "            # p = count(y) / count(Y)\n",
    "\n",
    "        #求label与feature同时发生的概率\n",
    "        P_xy = {}\n",
    "        for y in P_y.keys():\n",
    "            y_index = [i for i, label in enumerate(labels) if label == y]\n",
    "            # labels中出现y值的所有数值的下标索引\n",
    "            for j in range(len(features)):\n",
    "                # features[0] 在trainData[:,0]中出现的值的所有下标索引\n",
    "                x_index = [i for i, feature in enumerate(trainData[:,j]) if feature == features[j]]\n",
    "                xy_count = len(set(x_index) & set(y_index))\n",
    "                # set(x_index)&set(y_index)列出两个表相同的元素\n",
    "                pkey = str(features[j]) + '*' + str(y)\n",
    "                P_xy[pkey] = xy_count / float(len(labels))\n",
    "\n",
    "        #求条件概率\n",
    "        P = {}\n",
    "        for y in P_y.keys():\n",
    "            for x in features:\n",
    "                pkey = str(x) + '|' + str(y)\n",
    "                P[pkey] = P_xy[str(x)+'*'+str(y)] / float(P_y[y])\n",
    "                #P[X1/Y] = P[X1Y]/P[Y]\n",
    "\n",
    "        #求testData每条样例所属类别\n",
    "        F = {}\n",
    "        #testData每条样例属于各个类别的概率\n",
    "        for y in P_y:\n",
    "            F[y] = P_y[y]\n",
    "            for x in features:\n",
    "                F[y] = F[y]*P[str(x)+'|'+str(y)]\n",
    "                #P[y|X] = P[X|y]*P[y]/P[X]，分母相等，比较分子即可，\n",
    "                # 所以有F=P[X/y]*P[y]=P[x1/Y]*P[x2/Y]*P[x3|y]*P[x4|y]*P[y]\n",
    "\n",
    "        features_label = max(F, key=F.get)\n",
    "        #概率最大值对应的类别\n",
    "        return features_label\n",
    "\n",
    "     def test(self,trainData, labels, testData, testlabels):\n",
    "            correct = 0\n",
    "            for i in range(len(testData)):\n",
    "                # Outlook Temperature Humidity Wind\n",
    "                features = testData[i]\n",
    "                # 该特征应属于哪一类\n",
    "                result = nb.classify(trainData, labels, features)\n",
    "                print(features, '属于', result)\n",
    "                if nb.classify(trainData, labels, testData[i]) == testlabels[i]:\n",
    "                    correct += 1\n",
    "            accuracy = correct / float(len(testlabels))\n",
    "            print('准确率:',accuracy)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "            nb = NaiveBayes()\n",
    "            # 训练数据,测试数据\n",
    "            trainData, labels, testData, testlabels = nb.getTrainSet()\n",
    "            nb.test(trainData, labels, testData, testlabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调用sklearn函数的NaiveBayes算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/naive_bayes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes对于高斯分布的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 150 points: 2\n",
      "Accuracy: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "y_predict = gnb.fit(X_train,y_train).predict(X_test)\n",
    "\n",
    "print('Number of mislabeled points out of a total %d points: %d'\n",
    "     %(iris.data.shape[0],(y_test != y_predict).sum()))\n",
    "print('Accuracy:',((y_test == y_predict).sum()/len(y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multinominalNB 对于分类型数据，用于文本分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
